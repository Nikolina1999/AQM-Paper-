---
title: "First Try Replication"
author: "Nikolina Filiposki but code from previous authors (partly)"
date: "2024-04-07"
output:
  html_document:
    toc: true
    toc_float: true
    css: css/lab.css
  pdf_document:
    toc: yes
header-includes:
   - \usepackage[default]{sourcesanspro}
   - \usepackage[T1]{fontenc}
mainfont: SourceSansPro
---

```{r, setup, include = FALSE }
knitr::opts_chunk$set(echo = TRUE)

p_needed <-
  c("viridis", 
    "knitr", 
    "MASS", 
    "pROC", 
    "tidyverse",
    "stargazer",
    "haven",
    "estimatr",
    "dplyr",
    "fixest",
    "ggplot2",
    "tidyr")
    #"modelsummery") # not running yet, idk why 


packages <- rownames(installed.packages())
p_to_install <- p_needed[!(p_needed %in% packages)]

if (length(p_to_install) > 0) {
  install.packages(p_to_install)
}
sapply(p_needed, require, character.only = TRUE)

# This is an option for stargazer tables
#stargazer_opt <- ifelse(knitr::is_html_output(), "html")
# "latex"
```



```{r, load multilevel}
load("raw-data/multilevel_1-5-22.Rdata")
```



```{r, AP }
# Load the Data
load("cses_imd_r/cses_imd.RData")

# Just in case backup
cses <- cses_imd

# Select variables of interest
selected_vars <- select(cses, 
                        starts_with("IMD1006_"),
                        starts_with("IMD1005"), 
                        starts_with("IMD1004"),
                        starts_with("IMD3008_"),
                        starts_with("IMD1008_"),
                        starts_with("IMD5000_"),
                        starts_with("IMD5001_"), 
                        starts_with("IMD5003_"), 
                        starts_with("IMD5005_"))

# Choose country and year of interest (case selection like Adams et al. 2022)

# Generate a vector of countries
countries <- c("AUS", "AUT", "CAN", "DNK", "FIN", "FRA", "DEU", "GBR", "GRC", "ISL",
               "IRL", "ISR", "NLD", "NZL", "NOR", "PRT", "ESP", "SWE", "CHE", "USA")

# Generate a vector of years
years <- 1996:2017

# Create an empty vector to store combinations
cy_interest <- c()

# Loop through each combination of country and year
for (country in countries) {
  for (year in years) {
    # Check if the combination exists in  dataset
    if (any(grepl(paste0(country, "_", year), selected_vars$IMD1004))) {
      # If it exists, add it to the vector
      cy_interest <- c(cy_interest, paste(country, year, sep = "_"))
    }
  }
}

# Check 
print(cy_interest)

# Use filter() to select rows where IMD1004 is one of the countries in years of interest
selected_dataset <- filter(selected_vars, IMD1004 %in% cy_interest)

# View the selected dataset
# print(selected_dataset)

# Name identifier variable 'ID'

#names(selected_dataset)[names(selected_dataset) == "IMD1005"] <- "ID"
#names(multilevel_data)[names(multilevel_data) == "ID"] <- "ID"


# Merge datasets on common identifier
#merged_dataset <- left_join(multilevel_data, selected_dataset, by = "ID", all = TRUE)  # Change all = TRUE if you want to keep all rows


 
 rm(cses_imd)
 rm(cses)
 rm(selected_vars)
# rm(selected_d)
# rm(multilevel_data)

```

```{r}
# Filter out rows with values 96, 97, and 98 from variables IMD3008_A to IMD3008_I
selected_d <- selected_dataset %>%
  filter_at(vars(starts_with("IMD3008_")), all_vars(!. %in% c(96, 97, 98)))

# Filter out rows with value 99 in variables IMD3008_A to IMD3008_F
# selected_d <- selected_d %>%
#   filter_at(vars(ends_with("_A"), ends_with("_B"), ends_with("_C"), ends_with("_D"), ends_with("_E"), # ends_with("_F")), 
#             all_vars(!. %in% c(99)))
```



```{r, modify vote share}
# Divide variables by 100
selected_d[, c("IMD5001_A", "IMD5001_B", "IMD5001_C", "IMD5001_D", 
         "IMD5001_E", "IMD5001_F", "IMD5001_G", "IMD5001_H", "IMD5001_I")] <- 
  selected_d[, c("IMD5001_A", "IMD5001_B", "IMD5001_C", "IMD5001_D", 
           "IMD5001_E", "IMD5001_F", "IMD5001_G", "IMD5001_H", "IMD5001_I")] / 100

rm(selected_dataset)

```

Try out different API approches here...

First Reijan(2020)
```{r, Reijan 2020}
calculate_AP <- function(data) {
  # List of party preference variables (IMD3008_A to IMD3008_I)
  party_pref_vars <- c("IMD3008_A", "IMD3008_B", "IMD3008_C", "IMD3008_D", 
                       "IMD3008_E", "IMD3008_F", "IMD3008_G", "IMD3008_H", "IMD3008_I")
  
  # List of vote share variables (IMD5001_A to IMD5001_I)
  vote_share_vars <- c("IMD5001_A", "IMD5001_B", "IMD5001_C", "IMD5001_D", 
                       "IMD5001_E", "IMD5001_F", "IMD5001_G", "IMD5001_H", "IMD5001_I")
  
  # Initialize a vector to store AP scores for each party
  AP_scores <- matrix(0, nrow = nrow(data), ncol = length(party_pref_vars),
                      dimnames = list(NULL, party_pref_vars))
  
  # Loop through each respondent
  for (i in 1:nrow(data)) {
    # Get party preference and vote share data for the current respondent
    party_pref <- unlist(data[i, party_pref_vars])
    vote_share <- unlist(data[i, vote_share_vars])
    
    # Exclude missing values (99)
    valid_ratings <- which(!is.na(party_pref) & party_pref != 99)
    
    # Calculate the AP score for each party
    for (j in 1:length(party_pref_vars)) {
      if (j %in% valid_ratings) {
        in_party_pref <- party_pref[j]
        in_party_vote_share <- vote_share[j]
        combined_out_party_vote_share <- sum(vote_share[-j])
        out_party_prefs <- party_pref[-j]
        
        # Calculate the weighted difference between in-party and out-party preferences
        weighted_diff <- (in_party_pref - out_party_prefs) * (in_party_vote_share - combined_out_party_vote_share)
        
        # Sum up the weighted differences
        AP_scores[i, j] <- sum(weighted_diff)
      }
    }
  }
  
  # Return the relative AP scores for each party
  return(AP_scores)
}

# Selected_d is the dataset containing party preferences and vote shares
AP_scores <- calculate_AP(selected_d)
print(AP_scores)

#rm(AP_scores)
```


Second Wagner (2021)
$$
\begin{equation}
\text{Spread}_i = \sqrt{\frac{1}{n_p} \sum_{p=1}^{P} (\text{like}_{ip} - \bar{\text{like}}_i)^2}
\end{equation}


$$

```{r, Wagner 2021 Spread_i}
calculate_affective_polarization <- function(data) {
  # List of party preference variables (likeip)
  party_pref_vars <- c("IMD3008_A", "IMD3008_B", "IMD3008_C", "IMD3008_D", 
                       "IMD3008_E", "IMD3008_F", "IMD3008_G", "IMD3008_H", "IMD3008_I")
  
  # Initialize a vector to store affective polarization scores for each respondent
  affective_polarization_scores <- numeric(nrow(data))
  
  # Loop through each respondent
  for (i in 1:nrow(data)) {
    # Get party preference data for the current respondent
    party_pref <- unlist(data[i, party_pref_vars])
    
    # Exclude missing values (99)
    valid_ratings <- which(!is.na(party_pref) & party_pref != 99)
    
    # Calculate the weighted average party affect for the current respondent
    likei <- mean(party_pref[valid_ratings])
    
    # Calculate the spread for the current respondent
    spread_i <- sqrt(sum((party_pref[valid_ratings] - likei)^2) / length(valid_ratings))
    
    # Store the affective polarization score for the current respondent
    affective_polarization_scores[i] <- spread_i
  }
  
  # Return the affective polarization scores for each respondent
  return(affective_polarization_scores)
}

# Example usage:
# Assuming 'data' is your dataset containing party preferences
# Replace 'data' with the actual name of your dataset
affective_polarization_scores <- calculate_affective_polarization(selected_d)
print(affective_polarization_scores)

```


$$
\begin{equation}
Spread_i = \sqrt{\sum_{p=1}^{P} v_p \times (like_{ip} - like_i)^2}
\end{equation}
$$


where:
- \(Spread_i\) is the Weighted Affective Polarization score for respondent \(i\),
- \(P\) is the total number of parties,
- \(v_p\) is the vote share of party \(p\) (measured as a proportion with a range from 0 to 1),
- \(like_{ip}\) is the preference score given by respondent \(i\) for party \(p\), and
- \(like_i\) is the weighted average party affect for respondent \(i\).

$$
like_i = \sum_{p=1}^{P} (v_p \times like_{ip})
$$




```{r, spread like Wagner}
calculate_weighted_AP <- function(data) {
  # List of party preference variables (IMD3008_A to IMD3008_I)
  party_pref_vars <- c("IMD3008_A", "IMD3008_B", "IMD3008_C", "IMD3008_D", 
                       "IMD3008_E", "IMD3008_F", "IMD3008_G", "IMD3008_H", "IMD3008_I")
  
  # List of vote share variables (IMD5001_A to IMD5001_I)
  vote_share_vars <- c("IMD5001_A", "IMD5001_B", "IMD5001_C", "IMD5001_D", 
                       "IMD5001_E", "IMD5001_F", "IMD5001_G", "IMD5001_H", "IMD5001_I")
  
  # Initialize a vector to store weighted AP scores for each respondent
  weighted_AP_scores <- numeric(nrow(data))
  
  # Loop through each respondent
  for (i in 1:nrow(data)) {
    # Get party preference and vote share data for the current respondent
    party_pref <- unlist(data[i, party_pref_vars])
    vote_share <- unlist(data[i, vote_share_vars])
    
    # Exclude missing values (99)
    valid_ratings <- which(!is.na(party_pref) & party_pref != 99)
    
    # Calculate the weighted average party affect for the current respondent
    likei <- sum(party_pref[valid_ratings] * vote_share[valid_ratings])
    
    # Calculate the spread for the current respondent
    spread_i <- sqrt(sum((party_pref[valid_ratings] - likei)^2 * vote_share[valid_ratings]))
    
    # Store the weighted AP score for the current respondent
    weighted_AP_scores[i] <- spread_i
  }
  
  # Return the weighted AP scores for each respondent
  return(weighted_AP_scores)
}


weighted_AP_scores <- calculate_weighted_AP(selected_d)
print(weighted_AP_scores)

```



$$
\begin{equation}
Distance_i = \sqrt{\frac{1}{n_p} \sum_{p=1}^{P} v_p \times (like_{ip} - like_{\text{max},i})^2}
\end{equation}

$$


```{r, distance i}
calculate_mean_distance <- function(data) {
  # List of party preference variables (IMD3008_A to IMD3008_I)
  party_pref_vars <- c("IMD3008_A", "IMD3008_B", "IMD3008_C", "IMD3008_D", 
                       "IMD3008_E", "IMD3008_F", "IMD3008_G", "IMD3008_H", "IMD3008_I")
  
  # List of vote share variables (IMD5001_A to IMD5001_I)
  vote_share_vars <- c("IMD5001_A", "IMD5001_B", "IMD5001_C", "IMD5001_D", 
                       "IMD5001_E", "IMD5001_F", "IMD5001_G", "IMD5001_H", "IMD5001_I")
  
  # Initialize a vector to store mean-distance scores for each respondent
  mean_distance_scores <- numeric(nrow(data))
  
  # Loop through each respondent
  for (i in 1:nrow(data)) {
    # Get party preference and vote share data for the current respondent
    party_pref <- unlist(data[i, party_pref_vars])
    vote_share <- unlist(data[i, vote_share_vars])
    
    # Exclude missing values (99)
    valid_ratings <- which(!is.na(party_pref) & party_pref != 99)
    
    # Find the most-liked party
    most_liked_party_index <- which.max(party_pref[valid_ratings])
    likemax <- party_pref[valid_ratings][most_liked_party_index]
    
    # Calculate the mean-distance score for the current respondent
    num_parties <- length(valid_ratings)
    likemax_square <- likemax^2
    sum_distance <- sum((party_pref[valid_ratings] - likemax)^2 * vote_share[valid_ratings])
    mean_distance <- sqrt(sum_distance / num_parties)
    
    # Store the mean-distance score for the current respondent
    mean_distance_scores[i] <- mean_distance
  }
  
  # Return the mean-distance scores for each respondent
  return(mean_distance_scores)
}

mean_distance_scores <- calculate_mean_distance(selected_d)
print(mean_distance_scores)



```




Need that score for dyadic data (own approach from Wagner formula): 

$$
\text{Spread}_{ip} = \sqrt{v_p \times (\text{like}_{ip} - \bar{\text{like}}_i)^2}

$$
+ $Spread_ip$ represents the affective polarization score for respondent $i$ towards party $p$.
+ $v_p$ is the vote share of party $p$ (measured as a percentage with a range from 0 to 100).
+ $like_ip$ is the like-dislike score assigned by respondent $i$ for party $p$.
+ $likeË‰_i$ is the average like-dislike score assigned by respondent $i$ across all parties.

$$
like_i = \sum_{p=1}^{P} (v_p \times like_{ip})
$$



```{r, experiment correct but without ID}
calculate_affective_polarization_party <- function(data) {
  party_pref_vars <- c("IMD3008_A", "IMD3008_B", "IMD3008_C", "IMD3008_D", 
                       "IMD3008_E", "IMD3008_F", "IMD3008_G", "IMD3008_H", "IMD3008_I")
  
  vote_share_vars <- c("IMD5001_A", "IMD5001_B", "IMD5001_C", "IMD5001_D", 
                       "IMD5001_E", "IMD5001_F", "IMD5001_G", "IMD5001_H", "IMD5001_I")
  
  affective_polarization_scores <- matrix(0, nrow = nrow(data), ncol = length(party_pref_vars))
  
  for (i in 1:nrow(data)) {
    party_pref <- unlist(data[i, party_pref_vars])
    vote_share <- unlist(data[i, vote_share_vars]) 
    
    # Initialize affective polarization scores for the current respondent
    affective_polarization_row <- rep(0, length(party_pref))
    
    # Calculate the average like-dislike score for the current respondent
    valid_ratings <- which(!is.na(party_pref) & party_pref != 99)
    likei <- sum(party_pref[valid_ratings] * vote_share[valid_ratings])
    
    # Calculate the affective polarization score for non-missing party preferences
    valid_parties <- party_pref != 99
    affective_polarization_row[valid_parties] <- sqrt(vote_share[valid_parties] * (party_pref[valid_parties] - likei)^2)
    
    # Store the affective polarization scores for the current respondent
    affective_polarization_scores[i, ] <- affective_polarization_row
  }
  
  return(affective_polarization_scores)
}

# Example usage:
affective_polarization_party_scores <- calculate_affective_polarization_party(selected_d)
print(affective_polarization_party_scores)



# Convert matrix to data frame
AP_party_df <- as.data.frame(affective_polarization_party_scores)

# Add row names as a column
AP_party_df$Respondent <- rownames(AP_party_df)


AP_party_df <- AP_party_df %>% 
  rename(
    A = V1,
    B = V2,
    C = V3,
    D = V4,
    E = V5,
    F = V6,
    G = V7,
    H = V8,
    I = V9
  )


# Reshape data frame into long format
AP_party_long <- pivot_longer(AP_party_df, cols = -Respondent, names_to = "party_to", values_to = "WAP")

```



```{r, AP with ID correct one}
calculate_affective_polarization_party <- function(data, respondent_ids) {
  party_pref_vars <- c("IMD3008_A", "IMD3008_B", "IMD3008_C", "IMD3008_D", 
                       "IMD3008_E", "IMD3008_F", "IMD3008_G", "IMD3008_H", "IMD3008_I")
  
  vote_share_vars <- c("IMD5001_A", "IMD5001_B", "IMD5001_C", "IMD5001_D", 
                       "IMD5001_E", "IMD5001_F", "IMD5001_G", "IMD5001_H", "IMD5001_I")
  
  affective_polarization_scores <- matrix(0, nrow = nrow(data), ncol = length(party_pref_vars) + 1)  # +1 for the respondent ID
  
  for (i in 1:nrow(data)) {
    party_pref <- unlist(data[i, party_pref_vars])
    vote_share <- unlist(data[i, vote_share_vars]) 
    
    # Initialize affective polarization scores for the current respondent
    affective_polarization_row <- rep(0, length(party_pref))
    
    # Calculate the average like-dislike score for the current respondent
    valid_ratings <- which(!is.na(party_pref) & party_pref != 99)
    likei <- sum(party_pref[valid_ratings] * vote_share[valid_ratings])
    
    # Calculate the affective polarization score for non-missing party preferences
    valid_parties <- party_pref != 99
    affective_polarization_row[valid_parties] <- sqrt(vote_share[valid_parties] * (party_pref[valid_parties] - likei)^2)
    
    # Add respondent ID to the beginning of the row
    affective_polarization_row <- c(respondent_ids[i], affective_polarization_row)
    
    # Store the affective polarization scores for the current respondent
    affective_polarization_scores[i, ] <- affective_polarization_row
  }
  
#  colnames(affective_polarization_scores) <- c("ID", paste0("Affective_Polarization_", LETTERS[1:length(party_pref_vars)]))
  #colnames(affective_polarization_scores)[1] <- "ID"  # Rename the first column only
  
  return(affective_polarization_scores)
}

affective_polarization_party_scores <- calculate_affective_polarization_party(selected_d, selected_d$IMD1005)
print(affective_polarization_party_scores)


# Convert matrix to data frame
AP_party_df <- as.data.frame(affective_polarization_party_scores)

# Add row names as a column
AP_party_df$Respondent <- rownames(AP_party_df)


AP_party_df <- AP_party_df %>% 
  rename(
    ID = V1, 
    A = V2,
    B = V3,
    C = V4,
    D = V5,
    E = V6,
    F = V7,
    G = V8,
    H = V9,
    I = V10
  )


# Reshape data frame into long format
AP_party_long <- pivot_longer(AP_party_df, cols = c(-ID, -Respondent), names_to = "party_to", values_to = "WAP")

```



```{r, merge AP_party_long mit multilevel_data }

# Perform the merge
merged_data <- merge(AP_party_long, multilevel_data, by = c("party_to", "ID"))

```


```{r, perform first multilevel analysis}
table1.1 <-lm(party_like ~ to_pfeml + as.factor(cntryyr), data = merged_data)
summary(table1.1)


table1 <- lm(WAP ~ to_pfeml + as.factor(cntryyr), data = merged_data)
summary(table1)



table2 <- lm(WAP ~ to_pfeml + as.factor(country), data = merged_data)
summary(table2)

#table3 <- lm(WAP ~ to_pfeml + as.factor(year), data = merged_data)
#summary(table3)

count <- sum(merged_data$cntryyr == "Australia1996")
print(count)

```



```{r, simulation function}

sim_function <- function(lm_obj, nsim = 1000, scenario){
  
  # Step 1: Get the regression coefficients
  beta_hat <- coef(lm_obj)
  
  # Step 2: Generate sampling distribution
  
  # Step 2.1: Get the variance-covariance matrix.
  V_hat <-  vcov(lm_obj) 
  
  # Step 2.2: Draw from the multivariate normal distribution.
  S <- mvrnorm(nsim, beta_hat, V_hat)

  # Step 3: Choose interesting covariate values. 
  # Make sure the matrix multiplication also works for single scenarios
  if(is.null(nrow(scenario))){
    scenario <- matrix(scenario, nrow = 1)
  }
  
  # Print a message if the scenario does not fit the regression.
  if(ncol(scenario) != length(lm_obj$coefficients)){
    return(cat("The scenario has the wrong number of variables."))
  } 
  
  # Step 4: Calculate Quantities of Interest - 
  # Expected Values
  EV <- S %*% t(scenario)
  return(EV)
}

```

```{r, scenario}
s1 <- c(1, mean(merged_data$to_pfeml), rep(0, 19))
s2 <- c(1, 0.5, rep(0,19))

ev1 <- sim_function(table2, scenario = s1)
ev2 <- sim_function(table2, scenario = s2)

fd <- ev2- ev1
```





```{r, plot data usisng heatmap (not a good idea tbh)}


# Convert matrix to data frame
#weighted_AP_df <- as.data.frame(weighted_AP_dyadic)

# Add row names as a column
#weighted_AP_df$Respondent <- rownames(weighted_AP_df)

# Convert WAP to numeric
AP_party_long$WAP <- as.numeric(AP_party_long$WAP)

# Reshape data frame into long format
weighted_AP_long <- pivot_longer(weighted_AP_df, cols = -Respondent, names_to = "Party", values_to = "WAP")

# Generate heatmap
ggplot(data = AP_party_long, aes(x = party_to, y = Respondent, fill = WAP)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Dyadic Weighted AP Scores", x = "Party", y = "Respondent") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))


```



```{r, try to plot the data unsing KDE}
ggplot(data = AP_party_long, aes(x = WAP)) +
  geom_density(fill = "skyblue", color = "blue", alpha = 0.5) +
  labs(title = "Kernel Density Estimation (KDE) Plot of Dyadic Weighted AP Scores", x = "WAP Score", y = "Density") +
  xlim(0, 3)+
  theme_minimal()
```






